{"cells":[{"cell_type":"code","source":["outputTable = \"test_output\"\ndbutils.notebook.run(\"blog_contiguous\", timeout_seconds=180, arguments={\n  \"product\": \"dbfs:/FileStore/tables/test_sales-1.csv\",\n  \"output\": outputTable,\n})\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">IllegalArgumentException</span>                  Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-584830368896242&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> dbutils.notebook.run(&#34;blog_contiguous&#34;, timeout_seconds=180, arguments={\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>   <span class=\"ansi-blue-fg\">&#34;product&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#34;dbfs://FileStore/tables/test_sales.csv&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">&#34;output&#34;</span><span class=\"ansi-blue-fg\">:</span> outputTable<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> })\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1601294179656-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">run</span><span class=\"ansi-blue-fg\">(self, path, timeout_seconds, arguments, _NotebookHandler__databricks_internal_cluster_spec)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>                 arguments<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 __databricks_internal_cluster_spec<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">--&gt; 136</span><span class=\"ansi-red-fg\">                 self.shell.currentJobGroup)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    137</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    138</span>         <span class=\"ansi-green-fg\">def</span> __repr__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">IllegalArgumentException</span>: requirement failed: To enable notebook workflows, please upgrade your Databricks subscription.</div>"]}}],"execution_count":1},{"cell_type":"code","source":["spark.catalog.refreshTable(outputTable)\noutput = table(outputTable).cache()\ndisplay(output)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Month</th><th>Year</th><th>Product</th><th>Sales</th></tr></thead><tbody><tr><td>1</td><td>2002</td><td>cornflakes</td><td>2.9000000953674316</td></tr><tr><td>2</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr><tr><td>3</td><td>2002</td><td>cornflakes</td><td>2.9200000762939453</td></tr><tr><td>4</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr><tr><td>5</td><td>2002</td><td>cornflakes</td><td>2.869999885559082</td></tr><tr><td>6</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr><tr><td>7</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr><tr><td>8</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr><tr><td>9</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr><tr><td>10</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr><tr><td>11</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr><tr><td>12</td><td>2002</td><td>cornflakes</td><td>2.896666685740153</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"code","source":["import pyspark.sql.functions as F\n\nassert output.count() == 12\nassert output.groupby([\"Year\"]).count().collect()[0]['count']==12\nassert [output.select(\"Month\").collect()[i]['Month'] for i in range(0,output.count())]==[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":[""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"test","notebookId":584830368896241},"nbformat":4,"nbformat_minor":0}
